# OpenAI Agents SDK Best Practices

*Generated by AI Setup Deployment Script v2.36.0 on 2025-09-05 16:30:56 UTC*

A comprehensive guide for building agentic AI applications using the OpenAI Agents SDK, successor to the Swarm experimentation project.

## Overview

The OpenAI Agents SDK is a lightweight, production-ready Python framework for building agentic AI applications with minimal abstractions. It emphasizes simplicity while providing powerful capabilities for multi-agent workflows.

### Design Philosophy
- **Enough features to be useful, but few enough primitives to make it quick to learn**
- **Python-first design** with async/await patterns
- **Provider-agnostic** supporting OpenAI and 100+ other LLMs
- **Built-in safety** with guardrails and validation

## Core Primitives

### 1. Agents
LLMs equipped with instructions and tools that can:
- Execute specific tasks with specialized knowledge
- Use tools to interact with external systems
- Maintain conversation context and state
- Follow detailed instructions and constraints

### 2. Handoffs
Mechanisms that allow agents to delegate tasks:
- **Purpose**: Enable specialization and modular design
- **Use Case**: When different expertise is needed mid-conversation
- **Benefit**: Flexible conversational workflows
- **Challenge**: Harder to maintain global task view

### 3. Guardrails
Input validation and safety mechanisms:
- **Parallel Validation**: Run checks alongside agent execution
- **Early Breaking**: Stop processing if validation fails
- **Reliability**: Ensure consistent behavior and safety
- **Monitoring**: Track and log validation results

## Installation & Setup

### Prerequisites
- **Intermediate Python programming**: Functions, classes, async/await, type hints
- **Asynchronous programming**: Familiarity with async/await patterns
- **API Key**: OpenAI API key set as environment variable

### Installation
```bash
pip install openai-agents
```

### Environment Setup
```bash
export OPENAI_API_KEY="your-api-key-here"
```

## Agent Configuration Best Practices

### Core Agent Properties
```python
from agents import Agent

agent = Agent(
    name="SpecialistAgent",           # Descriptive, unique name
    instructions="You are a...",      # Clear, detailed system prompt
    model="gpt-4",                   # Choose appropriate model
    model_settings={                 # Optional model tuning
        "temperature": 0.1,
        "top_p": 0.9
    },
    tools=[...]                      # Relevant tools only
)
```

### Instruction Writing Guidelines
- **Be Specific**: Provide clear, detailed instructions
- **Define Scope**: Clearly outline what the agent should/shouldn't do
- **Include Context**: Provide relevant background information
- **Set Constraints**: Define boundaries and limitations
- **Use Examples**: Include example inputs/outputs when helpful

### Tool Selection
- **Minimize Tools**: Only include necessary tools
- **Group Related**: Organize tools by functionality
- **Document Usage**: Provide clear tool descriptions
- **Test Thoroughly**: Validate tool behavior before deployment

## Multi-Agent Collaboration Patterns

### 1. Agent-as-Tool Pattern (Recommended)
**Best for**: Transparency, auditability, and scalability

```python
# Central orchestrator agent
manager_agent = Agent(
    name="TaskManager",
    instructions="Coordinate specialists to complete complex tasks",
    tools=[specialist_agent_1, specialist_agent_2, specialist_agent_3]
)

# Specialist agents
research_agent = Agent(
    name="Researcher", 
    instructions="Conduct thorough research on given topics"
)

analysis_agent = Agent(
    name="Analyst",
    instructions="Analyze data and provide insights"
)
```

**Benefits**:
- Single thread of control
- Parallel execution of subtasks
- Transparent reasoning chain
- Easy debugging and monitoring
- Consistent orchestration

**Use Cases**:
- Complex workflows with multiple steps
- Tasks requiring different expertise areas
- Situations requiring audit trails
- Parallel processing needs

### 2. Handoff Pattern
**Best for**: Conversational flows and context switching

```python
# Agent A starts task
result = agent_a.process(task)

# Hand off to specialist when needed
if requires_specialization:
    result = handoff_to(specialist_agent, context=result)
```

**Benefits**:
- Natural conversation flow
- Context preservation across agents
- Flexible task routing
- Specialized expertise application

**Use Cases**:
- Customer service workflows
- Multi-step consultative processes
- Context-dependent task routing
- Sequential specialized processing

## Implementation Best Practices

### 1. Modularity and Specialization
```python
# Good: Focused, single-purpose agents
content_writer = Agent(
    name="ContentWriter",
    instructions="Write engaging, SEO-optimized content",
    tools=[seo_tools, grammar_check]
)

research_agent = Agent(
    name="Researcher", 
    instructions="Find and validate information sources",
    tools=[web_search, fact_check]
)

# Avoid: Overly broad, multi-purpose agents
```

### 2. Error Handling and Resilience
```python
from agents import Runner

try:
    result = Runner.run_sync(
        agent=my_agent,
        messages="Process this task",
        max_iterations=10,  # Prevent infinite loops
        timeout=60         # Set reasonable timeouts
    )
except AgentError as e:
    # Handle agent-specific errors
    logger.error(f"Agent failed: {e}")
    fallback_response = handle_agent_failure(e)
except TimeoutError as e:
    # Handle timeout scenarios
    logger.warning(f"Agent timed out: {e}")
    partial_result = get_partial_results()
```

### 3. Tracing and Monitoring
```python
# Built-in tracing automatically enabled
result = Runner.run_sync(agent, "Task description")

# Access trace information
print(f"Total iterations: {result.trace.iterations}")
print(f"Tool calls made: {len(result.trace.tool_calls)}")
print(f"Execution time: {result.trace.duration}")

# Custom logging
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("agents")
```

### 4. Input Validation with Guardrails
```python
from agents import Guardrail

# Input validation guardrail
input_validator = Guardrail(
    name="InputValidator",
    check_function=validate_input_format,
    error_message="Invalid input format provided"
)

# Safety guardrail
safety_check = Guardrail(
    name="SafetyCheck", 
    check_function=check_content_safety,
    error_message="Content violates safety guidelines"
)

agent = Agent(
    name="ProcessingAgent",
    instructions="Process user requests safely",
    guardrails=[input_validator, safety_check]
)
```

## Advanced Patterns

### 1. Parallel Agent Execution
```python
import asyncio
from agents import Runner

async def parallel_analysis(data):
    tasks = [
        Runner.run_async(macro_agent, f"Analyze macro trends: {data}"),
        Runner.run_async(fundamental_agent, f"Fundamental analysis: {data}"),
        Runner.run_async(quant_agent, f"Quantitative analysis: {data}")
    ]
    
    results = await asyncio.gather(*tasks)
    return combine_analysis_results(results)
```

### 2. Dynamic Agent Selection
```python
def select_agent(task_type, complexity):
    if task_type == "research" and complexity == "high":
        return expert_research_agent
    elif task_type == "research" and complexity == "low":
        return basic_research_agent
    elif task_type == "analysis":
        return analysis_agent
    else:
        return general_agent

# Use in workflow
agent = select_agent(task.type, task.complexity)
result = Runner.run_sync(agent, task.description)
```

### 3. Agent State Management
```python
class StatefulWorkflow:
    def __init__(self):
        self.context = {}
        self.history = []
    
    def process_step(self, agent, task):
        # Add context to agent instructions
        contextual_instructions = f"""
        {agent.instructions}
        
        Previous context: {self.context}
        Task history: {self.history[-3:]}  # Last 3 tasks
        """
        
        agent.instructions = contextual_instructions
        result = Runner.run_sync(agent, task)
        
        # Update state
        self.context.update(result.context)
        self.history.append((task, result))
        
        return result
```

## Testing and Validation

### 1. Unit Testing Agents
```python
import pytest
from agents import Agent, Runner

def test_research_agent():
    agent = Agent(
        name="TestResearcher",
        instructions="Research the given topic briefly"
    )
    
    result = Runner.run_sync(agent, "Research Python testing frameworks")
    
    assert result.final_output is not None
    assert len(result.final_output) > 50  # Meaningful response
    assert "pytest" in result.final_output.lower()  # Expected content

def test_agent_with_tools():
    mock_tool = create_mock_tool()
    agent = Agent(
        name="TestAgent",
        instructions="Use tools to complete tasks",
        tools=[mock_tool]
    )
    
    result = Runner.run_sync(agent, "Use the tool to get information")
    
    assert mock_tool.called
    assert result.trace.tool_calls > 0
```

### 2. Integration Testing
```python
def test_multi_agent_workflow():
    manager = Agent(
        name="Manager",
        instructions="Coordinate research and analysis",
        tools=[research_agent, analysis_agent]
    )
    
    result = Runner.run_sync(
        manager, 
        "Research market trends and provide analysis"
    )
    
    # Verify both agents were used
    assert "research" in result.trace.agent_calls
    assert "analysis" in result.trace.agent_calls
    
    # Verify output quality
    assert len(result.final_output) > 200
    assert "trends" in result.final_output.lower()
```

### 3. Performance Testing
```python
import time

def test_agent_performance():
    start_time = time.time()
    
    result = Runner.run_sync(
        performance_agent,
        "Complete this standard task"
    )
    
    execution_time = time.time() - start_time
    
    assert execution_time < 30  # Max 30 seconds
    assert result.trace.iterations < 10  # Reasonable iteration count
```

## Security and Safety

### 1. Input Sanitization
```python
def sanitize_input(user_input):
    # Remove potential injection attempts
    cleaned = re.sub(r'[<>"\']', '', user_input)
    
    # Length limits
    if len(cleaned) > 1000:
        cleaned = cleaned[:1000]
    
    return cleaned

# Apply before agent processing
safe_input = sanitize_input(user_request)
result = Runner.run_sync(agent, safe_input)
```

### 2. Tool Access Control
```python
# Restrict tool access based on context
def get_allowed_tools(user_role, task_type):
    base_tools = [search_tool, format_tool]
    
    if user_role == "admin":
        base_tools.extend([admin_tool, delete_tool])
    
    if task_type == "analysis":
        base_tools.append(analysis_tool)
    
    return base_tools

tools = get_allowed_tools(current_user.role, task.type)
agent = Agent(name="RestrictedAgent", tools=tools)
```

### 3. Output Filtering
```python
def filter_sensitive_output(result):
    sensitive_patterns = [
        r'\b\d{3}-\d{2}-\d{4}\b',  # SSN
        r'\b\d{16}\b',             # Credit card
        r'api[_-]?key[_-]?[:\s]*[\w\-]+',  # API keys
    ]
    
    filtered_output = result.final_output
    for pattern in sensitive_patterns:
        filtered_output = re.sub(pattern, '[REDACTED]', filtered_output)
    
    return filtered_output
```

## Performance Optimization

### 1. Model Selection
```python
# Choose appropriate models for tasks
fast_agent = Agent(
    name="QuickResponder",
    model="gpt-3.5-turbo",  # Faster, cheaper for simple tasks
    instructions="Provide quick responses"
)

complex_agent = Agent(
    name="DeepThinker", 
    model="gpt-4",  # More capable for complex reasoning
    instructions="Perform detailed analysis"
)
```

### 2. Caching Strategies
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_agent_call(agent_name, task_hash):
    agent = get_agent(agent_name)
    return Runner.run_sync(agent, task_hash)

# Use for repeated similar tasks
result = cached_agent_call("researcher", hash(task_description))
```

### 3. Batch Processing
```python
async def batch_process_tasks(agent, tasks):
    # Process in batches to manage resources
    batch_size = 5
    results = []
    
    for i in range(0, len(tasks), batch_size):
        batch = tasks[i:i+batch_size]
        batch_tasks = [
            Runner.run_async(agent, task) 
            for task in batch
        ]
        batch_results = await asyncio.gather(*batch_tasks)
        results.extend(batch_results)
        
        # Brief pause between batches
        await asyncio.sleep(1)
    
    return results
```

## Monitoring and Observability

### 1. Metrics Collection
```python
import time
from collections import defaultdict

class AgentMetrics:
    def __init__(self):
        self.call_counts = defaultdict(int)
        self.execution_times = defaultdict(list)
        self.error_counts = defaultdict(int)
    
    def record_call(self, agent_name, execution_time, success=True):
        self.call_counts[agent_name] += 1
        self.execution_times[agent_name].append(execution_time)
        
        if not success:
            self.error_counts[agent_name] += 1
    
    def get_stats(self, agent_name):
        times = self.execution_times[agent_name]
        return {
            "total_calls": self.call_counts[agent_name],
            "avg_time": sum(times) / len(times) if times else 0,
            "error_rate": self.error_counts[agent_name] / self.call_counts[agent_name]
        }

# Global metrics instance
metrics = AgentMetrics()
```

### 2. Logging Best Practices
```python
import logging
import json

# Structured logging for agent activities
def log_agent_activity(agent_name, task, result, execution_time):
    log_data = {
        "timestamp": time.time(),
        "agent": agent_name,
        "task_hash": hash(task),
        "success": result.success,
        "execution_time": execution_time,
        "iterations": result.trace.iterations,
        "tool_calls": len(result.trace.tool_calls)
    }
    
    logging.info(json.dumps(log_data))
```

### 3. Health Checks
```python
def health_check_agent(agent):
    try:
        start_time = time.time()
        result = Runner.run_sync(
            agent, 
            "Respond with 'OK' if you're functioning normally",
            timeout=10
        )
        execution_time = time.time() - start_time
        
        return {
            "healthy": "OK" in result.final_output,
            "response_time": execution_time,
            "last_check": time.time()
        }
    except Exception as e:
        return {
            "healthy": False,
            "error": str(e),
            "last_check": time.time()
        }
```

## Common Patterns and Use Cases

### 1. Research and Analysis Pipeline
```python
research_pipeline = Agent(
    name="ResearchPipeline",
    instructions="Coordinate comprehensive research workflow",
    tools=[
        web_research_agent,
        data_analysis_agent,
        fact_checking_agent,
        report_generation_agent
    ]
)
```

### 2. Customer Service Workflow
```python
customer_service = Agent(
    name="CustomerServiceHub",
    instructions="Handle customer inquiries with appropriate routing",
    tools=[
        intent_classification_agent,
        product_support_agent,
        billing_support_agent,
        escalation_agent
    ]
)
```

### 3. Content Creation Pipeline
```python
content_pipeline = Agent(
    name="ContentCreator",
    instructions="Create high-quality content through collaboration",
    tools=[
        research_agent,
        outline_agent,
        writing_agent,
        editing_agent,
        seo_optimization_agent
    ]
)
```

## Migration from Swarm

If migrating from the experimental Swarm framework:

### Key Differences
- **Production Ready**: Agents SDK is production-ready vs. experimental
- **Enhanced Tooling**: Better tracing, validation, and monitoring
- **Improved API**: More consistent and intuitive interface
- **Performance**: Optimized for real-world usage patterns

### Migration Steps
1. Update import statements: `from agents import Agent` instead of `from swarm import Agent`
2. Review agent configurations for new parameters
3. Update tool definitions to use new schema
4. Implement guardrails where appropriate
5. Add proper error handling and monitoring
6. Test thoroughly in non-production environment

## Resources and Further Reading

### Official Documentation
- [OpenAI Agents SDK GitHub](https://github.com/openai/openai-agents-python)
- [OpenAI Platform Documentation](https://platform.openai.com/docs/guides/agents)
- [OpenAI Cookbook Examples](https://cookbook.openai.com/examples/agents_sdk/)

### Community Resources
- [Multi-Agent Collaboration Examples](https://cookbook.openai.com/examples/agents_sdk/multi-agent-portfolio-collaboration/)
- [Best Practices Discussions](https://community.openai.com)

### Tools and Integrations
- Compatible with 100+ LLM providers
- OpenAI evaluation and fine-tuning tools
- Third-party monitoring and observability platforms

---

*Last updated: [Current Date]*
*This document should be updated as the OpenAI Agents SDK evolves and new patterns emerge.*
